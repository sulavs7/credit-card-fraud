{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: d:\\PROJECTS\\cnns\\creditCardFraud\\models\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GkNGESQdpMMp"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
        "from scipy.stats import randint,uniform\n",
        "from sklearn.metrics import make_scorer, recall_score\n",
        "from evaluation import evaluate_classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WOz6VZlGpPjD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
            "C:\\Users\\97798\\AppData\\Local\\Temp\\ipykernel_4436\\2077961581.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  data=joblib.load(\"D:\\PROJECTS\\cnns\\creditCardFraud\\data\\without_smote_preprocessed_data.pkl\")\n"
          ]
        }
      ],
      "source": [
        "data=joblib.load(\"D:\\PROJECTS\\cnns\\creditCardFraud\\data\\without_smote_preprocessed_data.pkl\")\n",
        "X_train=data[\"X_train_scaled\"]\n",
        "X_test=data[\"X_test_scaled\"]\n",
        "y_train=data[\"y_train\"]\n",
        "y_test=data[\"y_test\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2LiwsYbpRUC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "scorer = make_scorer(recall_score, average='binary')\n",
        "\n",
        "param_grid= {\n",
        "    'learning_rate': [0.01, 0.05],  # Lower rates for more boosting rounds\n",
        "    'max_depth': [4, 5],            # Keep moderate depth\n",
        "    'n_estimators': [200, 300],     # More trees to compensate for lower learning rate\n",
        "    'min_child_weight': [5, 10],    # Maintain strong regularization\n",
        "    'gamma': [0.1, 0.2],\n",
        "    'subsample': [0.6, 0.8],        # Slightly more data per tree\n",
        "    'colsample_bytree': [0.6, 0.8],\n",
        "    'reg_alpha': [0.5, 1.0],        # Stronger L1 regularization\n",
        "    'reg_lambda': [0.1, 0.5]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxwBLlh9pUkB",
        "outputId": "da450d16-18c1-49a3-97e6-11d563b97c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[0]\tvalidation_0-aucpr:0.61553\n",
            "[1]\tvalidation_0-aucpr:0.66498\n",
            "[2]\tvalidation_0-aucpr:0.69335\n",
            "[3]\tvalidation_0-aucpr:0.69660\n",
            "[4]\tvalidation_0-aucpr:0.71235\n",
            "[5]\tvalidation_0-aucpr:0.71189\n",
            "[6]\tvalidation_0-aucpr:0.72283\n",
            "[7]\tvalidation_0-aucpr:0.72262\n",
            "[8]\tvalidation_0-aucpr:0.72592\n",
            "[9]\tvalidation_0-aucpr:0.72486\n",
            "[10]\tvalidation_0-aucpr:0.72676\n",
            "[11]\tvalidation_0-aucpr:0.72953\n",
            "[12]\tvalidation_0-aucpr:0.72476\n",
            "[13]\tvalidation_0-aucpr:0.72368\n",
            "[14]\tvalidation_0-aucpr:0.72273\n",
            "[15]\tvalidation_0-aucpr:0.72000\n",
            "[16]\tvalidation_0-aucpr:0.72248\n",
            "[17]\tvalidation_0-aucpr:0.72323\n",
            "[18]\tvalidation_0-aucpr:0.72539\n",
            "[19]\tvalidation_0-aucpr:0.72494\n",
            "[20]\tvalidation_0-aucpr:0.72474\n",
            "\n",
            "Best hyperparameters: {'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.6}\n"
          ]
        }
      ],
      "source": [
        "xg_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='aucpr',  # Use PR-AUC as eval metric\n",
        "    scale_pos_weight=100,\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "# Use stratified k-fold\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Configure search\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xg_model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=50,\n",
        "    scoring=scorer,\n",
        "    cv=cv,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)]\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"\\nBest hyperparameters: {random_search.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrXAiQFQrMeJ"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_xg_model = random_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXHYE8ci1tQc",
        "outputId": "07333e93-f5c5-40b4-e672-1647f51883b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.6, device=None, early_stopping_rounds=10,\n",
            "              enable_categorical=False, eval_metric='aucpr', feature_types=None,\n",
            "              gamma=0.2, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=None, ...)\n"
          ]
        }
      ],
      "source": [
        "print(best_xg_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIlcxzyW1ztc"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = best_xg_model.predict(X_test)\n",
        "y_train_pred=best_xg_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxNEcmZU2VQI",
        "outputId": "8720ad85-4244-41f0-9701-db3ede8c1bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train metrics:\n",
            "Accuracy Score: 0.9994669133844392\n",
            "Recall Score: 0.9046537856808728\n",
            "Precision Score: 0.9308270627626765\n",
            "F1 Score: 0.9173289957538422\n",
            "Confusion matrix: [[226553     49]\n",
            " [    72    306]]\n",
            "PR-AUC: 0.8294\n",
            "\n",
            "Test metrics:\n",
            "Accuracy Score: 0.9993303492757198\n",
            "Recall Score: 0.863051983102449\n",
            "Precision Score: 0.9256965074136168\n",
            "F1 Score: 0.8918777818425705\n",
            "Confusion matrix: [[56639    12]\n",
            " [   26    69]]\n",
            "PR-AUC: 0.7536\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix,auc\n",
        "\n",
        "# Train metrics\n",
        "print(\"Train metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_train, y_train_pred))  # Corrected to y_train\n",
        "print(\"Recall Score:\", recall_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Precision Score:\", precision_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"F1 Score:\", f1_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_train, y_train_pred))  # Corrected to y_train\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_xg_model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_train, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Test metrics\n",
        "print(\"\\nTest metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Recall Score:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision Score:\", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_xg_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PFDPD5n_1wj"
      },
      "source": [
        "Threshold Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq57yL7URrYt"
      },
      "outputs": [],
      "source": [
        "y_proba = best_xg_model.predict_proba(X_test)[:, 1]\n",
        "new_threshold = 0.30  # Lower = higher recall\n",
        "y_pred = (y_proba >= new_threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkVnX_8iR1RR",
        "outputId": "19235afe-c63d-4d3f-deda-95beace7237a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train metrics:\n",
            "Accuracy Score: 0.9994669133844392\n",
            "Recall Score: 0.9046537856808728\n",
            "Precision Score: 0.9308270627626765\n",
            "F1 Score: 0.9173289957538422\n",
            "Confusion matrix: [[226553     49]\n",
            " [    72    306]]\n",
            "PR-AUC: 0.8294\n",
            "\n",
            "Test metrics:\n",
            "Accuracy Score: 0.9989602791386177\n",
            "Recall Score: 0.8891382973682818\n",
            "Precision Score: 0.8301717418612746\n",
            "F1 Score: 0.8572275175325197\n",
            "Confusion matrix: [[56613    38]\n",
            " [   21    74]]\n",
            "PR-AUC: 0.7536\n"
          ]
        }
      ],
      "source": [
        "# Train metrics\n",
        "print(\"Train metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_train, y_train_pred))  # Corrected to y_train\n",
        "print(\"Recall Score:\", recall_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Precision Score:\", precision_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"F1 Score:\", f1_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_train, y_train_pred))  # Corrected to y_train\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_xg_model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_train, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Test metrics\n",
        "print(\"\\nTest metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Recall Score:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision Score:\", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_xg_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH0BZUwyCd6D"
      },
      "source": [
        "Threshold tuning also gave more worse result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orOtYX85DGDI",
        "outputId": "78d69d21-017f-4107-a08b-be9fe39905ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgb_model.pkl']"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(best_xg_model, 'xgb_model.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
