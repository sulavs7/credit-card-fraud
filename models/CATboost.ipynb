{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8UR7oHNY4zX",
        "outputId": "d3a19d4c-dd63-4a34-9c3a-30e804f66d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Du7pvJefWyVp"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier, Pool\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV, StratifiedKFold\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, confusion_matrix, accuracy_score, average_precision_score\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'catboost'"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score, average_precision_score\n",
        "from scipy.stats import uniform, randint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyT-knkOXdBR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load data\n",
        "data = joblib.load(\"/content/without_smote_preprocessed_data.pkl\")\n",
        "X_train = data[\"X_train_scaled\"]\n",
        "X_test = data[\"X_test_scaled\"]\n",
        "y_train = data[\"y_train\"]\n",
        "y_test = data[\"y_test\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiKhUQ90XefR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Define model\n",
        "cat_model = CatBoostClassifier(\n",
        "    scale_pos_weight=100,\n",
        "    eval_metric='PRAUC',\n",
        "    early_stopping_rounds=10,\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxd33_jUYJNQ"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define hyperparameter search space\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],  # Discrete values work better than uniform\n",
        "    'depth': [4, 5, 6],                   # Focus near XGBoost's best depth (5)\n",
        "    'l2_leaf_reg': [0.1, 0.5, 1, 5],      # Wider regularization range\n",
        "    'subsample': [0.6, 0.8],               # Test higher subsampling\n",
        "    'iterations': [100, 200],              # Fewer trees for faster tuning\n",
        "    'grow_policy': ['SymmetricTree', 'Depthwise']  # Tree growth strategies\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ7BuWYTZjdF"
      },
      "outputs": [],
      "source": [
        "# Step 3: StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es-gQ0oDZlol",
        "outputId": "9d9ce39f-4874-4070-bcce-a81b38606a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "Best hyperparameters: {'subsample': 0.6, 'learning_rate': 0.1, 'l2_leaf_reg': 5, 'iterations': 200, 'grow_policy': 'Depthwise', 'depth': 6}\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Randomized Search\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=cat_model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=30,\n",
        "    scoring='average_precision',\n",
        "    cv=cv,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#Step 5: Fit RandomizedSearchCV to the training data\n",
        "random_search.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)]\n",
        ")\n",
        "\n",
        "# Best model\n",
        "best_cat_model = random_search.best_estimator_\n",
        "print(\"\\nBest hyperparameters:\", random_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfLIbS7eaNpI",
        "outputId": "3897ff64-a0b3-4578-d0c5-41079d21762b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<catboost.core.CatBoostClassifier object at 0x7c5e8f2f02d0>\n"
          ]
        }
      ],
      "source": [
        "print(best_cat_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZU3of3paZhC"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = best_cat_model.predict(X_test)\n",
        "y_train_pred=best_cat_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbUoD0YaeC4",
        "outputId": "67dff0cd-86fc-4c8b-ab01-fe65d1e71755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train metrics:\n",
            "Accuracy Score: 0.999052779980615\n",
            "Recall Score: 0.9334983594058976\n",
            "Precision Score: 0.8325468192000525\n",
            "F1 Score: 0.8763413850061352\n",
            "Confusion matrix: [[226437    165]\n",
            " [    50    328]]\n",
            "PR-AUC: 0.8221\n",
            "\n",
            "Test metrics:\n",
            "Accuracy Score: 0.9990131463010609\n",
            "Recall Score: 0.8839104433516758\n",
            "Precision Score: 0.8409272828586623\n",
            "F1 Score: 0.8611389852905318\n",
            "Confusion matrix: [[56617    34]\n",
            " [   22    73]]\n",
            "PR-AUC: 0.7244\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix,auc\n",
        "\n",
        "# Train metrics\n",
        "print(\"Train metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_train, y_train_pred))  # Corrected to y_train\n",
        "print(\"Recall Score:\", recall_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Precision Score:\", precision_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"F1 Score:\", f1_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_train, y_train_pred))  # Corrected to y_train\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_cat_model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_train, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Test metrics\n",
        "print(\"\\nTest metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Recall Score:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision Score:\", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_cat_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjDItmIkaqOJ"
      },
      "source": [
        "Threshold Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYJC8e8wanrH"
      },
      "outputs": [],
      "source": [
        "y_proba = best_cat_model.predict_proba(X_test)[:, 1]\n",
        "new_threshold = 0.6 # Lower = higher recall\n",
        "y_pred = (y_proba >= new_threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnpz6GglatJ1",
        "outputId": "f9093f74-136f-486e-dda3-69538245aced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train metrics:\n",
            "Accuracy Score: 0.999052779980615\n",
            "Recall Score: 0.9334983594058976\n",
            "Precision Score: 0.8325468192000525\n",
            "F1 Score: 0.8763413850061352\n",
            "Confusion matrix: [[226437    165]\n",
            " [    50    328]]\n",
            "PR-AUC: 0.8221\n",
            "\n",
            "Test metrics:\n",
            "Accuracy Score: 0.9992774821132767\n",
            "Recall Score: 0.8840428328946671\n",
            "Precision Score: 0.896544969387019\n",
            "F1 Score: 0.8901934039659647\n",
            "Confusion matrix: [[56632    19]\n",
            " [   22    73]]\n",
            "PR-AUC: 0.7244\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train metrics\n",
        "print(\"Train metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_train, y_train_pred))  # Corrected to y_train\n",
        "print(\"Recall Score:\", recall_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Precision Score:\", precision_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"F1 Score:\", f1_score(y_train, y_train_pred, average=\"macro\"))  # Corrected to y_train\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_train, y_train_pred))  # Corrected to y_train\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_cat_model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_train, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Test metrics\n",
        "print(\"\\nTest metrics:\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Recall Score:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision Score:\", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get predicted probabilities for the positive class (fraud)\n",
        "y_proba = best_cat_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Compute PR-AUC\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjgbRMjkazlb",
        "outputId": "2540da50-e86c-4d62-884f-b0bbf92c4e86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cat_model.pkl']"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(best_cat_model, 'cat_model.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
